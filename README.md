Google Calendar ELT Pipeline (Fivetran â†’ Snowflake â†’ dbt â†’ GitHub Actions)

This project is a compact, production-style ELT pipeline built as a Data Engineering portfolio piece.
It demonstrates automated data ingestion, transformation, testing and CI/CD using modern cloud tools.

ğŸ”§ Tech Stack

Fivetran â€“ automated ingestion of Google Calendar data
Snowflake â€“ cloud data warehouse (raw + analytics schemas)
dbt Core â€“ transformations, tests, documentation
GitHub Actions â€“ automated daily dbt build (CI/CD)

ğŸš€ What the Pipeline Does

Replicates Google Calendar events + attendees via Fivetran

Stores raw data in Snowflake

Cleans and models data into:

staging layer (raw â†’ standardized)

intermediate layer (events + attendees join)

marts (analytics tables)

Runs tests + builds models automatically via GitHub Actions

ğŸ§± Data Models (dbt)

Staging:

stg_events

stg_attendee

Intermediate:

int_events_with_attendees â€“ enriched event records with attendee-level detail

Marts:

calendar_events_summary â€“ event metrics (attendee counts, statuses)

attendees_status_summary â€“ user-level activity statistics

events_activity_over_time â€“ daily/weekly event participation trends

All marts include dbt tests (not_null, unique) and documentation.

âš™ï¸ CI/CD (GitHub Actions)

Automated workflow runs:

pip install dbt-core dbt-snowflake

generates profiles.yml from GitHub Secrets

executes dbt build on schedule or manual trigger

This mimics a production-grade orchestration setup.

ğŸ“ˆ What This Project Demonstrates

âœ” End-to-end ELT pipeline

âœ” Working dbt DAG (staging â†’ intermediate â†’ marts)

âœ” Data quality tests

âœ” Automated builds via GitHub Actions

âœ” Clean, modular SQL transformations

âœ” Cloud-native stack used by modern Data Engineering teams


ğŸ“Œ Status

Fully functional and automated.
A clear example of a real-world analytical pipeline using modern DE tooling.

